# -*- coding: utf-8 -*-
"""LAB3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1c0fYU_lPq4xQohtd-xGKHcl2sVaEJh8E

# LABORATORIO 3
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns; sns.set()  # for plot styling

from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_samples, silhouette_score
from sklearn.preprocessing import MinMaxScaler

from matplotlib import cm
from mpl_toolkits.mplot3d import Axes3D # for 3D plots

seed = 161

# Composicion de pipelines
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import PolynomialFeatures
from sklearn.preprocessing import MinMaxScaler

# Regresion lineal
from sklearn.linear_model import LinearRegression

# Importar/ Exportar modelos
from joblib import dump, load

# Metricas
from sklearn.metrics import mean_squared_error as mse

# q-q plots
import scipy.stats as stats

"""Leemos el archivo"""

df=pd.read_csv('202210_Laboratorio3_data_DatosTrain.csv', sep=',', encoding = 'utf-8')

"""Miramos cuantas columnas y filas tiene"""

df.shape

"""Miramos los tipos de datos suministrados"""

df.info()

"""Miramos los primero 10 datos para echar un primer vistazo a los datos"""

# Ver primeros registros
df.head()

"""Hacemos un análisis descriptivo de los datos para ver como se comportan sus valores"""

# Analisis descriptivo
df.describe()

"""**Limpieza**"""

df.drop("Unnamed: 0",axis=1)

#Revisamos datos faltantes
display(df.isnull().sum())

"""# **Modelado**

"""

# Eliminamos los registros que tienen la variable objetivo nula
df = df.dropna(subset = ['Life expectancy'])

sns.pairplot(df, height=3, y_vars = 'Life expectancy', x_vars = df.columns[0:5], kind='scatter')
sns.pairplot(df, height=3, y_vars = 'Life expectancy', x_vars = df.columns[5:10], kind='scatter')
sns.pairplot(df, height=3, y_vars = 'Life expectancy', x_vars = df.columns[10:], kind='scatter')

f = plt.figure(figsize=(19, 15))
plt.matshow(df.corr(), fignum=f.number, cmap = 'seismic')
plt.xticks(range(df.select_dtypes(['number']).shape[1]), df.select_dtypes(['number']).columns, fontsize=14, rotation=45)
plt.yticks(range(df.select_dtypes(['number']).shape[1]), df.select_dtypes(['number']).columns, fontsize=14)
cb = plt.colorbar()
_ = cb.ax.tick_params(labelsize=14)

# Preprocesamiento
# Se usa un transformador para seleccionar unicamente las columnas que se quieren usar
selected_cols = ['HIV/AIDS','BMI','Income composition of resources','Adult Mortality']

pre = [('initial',ColumnTransformer([("selector", 'passthrough',selected_cols)])),]

# Modelo
model = [('model', LinearRegression())]

# Decalra el pipeline
pipeline = Pipeline(pre+model)

# Extraemos las variables explicativas y objetivo para entrenar
X = df.drop('Life expectancy', axis = 1)
y = df['Life expectancy']

pipeline = pipeline.fit(X,y)

# Visualizamos la regresion lineal en cada dimension
f, axs = plt.subplots(1, len(selected_cols), sharey=True, figsize = (12,4))

for i in range(len(selected_cols)):

    pos_col = i
    col = selected_cols[pos_col]

    # Variable x
    x = X[col]
    # Pendiente
    m = pipeline['model'].coef_[pos_col]
    # Interceto
    b = pipeline['model'].intercept_

    axs[i].plot(x, y, 'o', alpha = 0.1)
    axs[i].plot(x, x*m + b)
    axs[i].set_title(col)

"""# Exportación del modelo

"""

# Usamos la lbreria joblib
filename = 'pipeline.joblib'
# Se guarda (Exportación del modelo)
dump(pipeline, filename)

# Se lee
p2 = load(filename)
p2

"""# Coeficientes"""

pipeline['model'].coef_

# En DataFrame
pd.DataFrame({'columns':selected_cols, 'coef':pipeline['model'].coef_})

"""# Métricas"""

p2.score(X,y)

y_true = y
y_predicted = p2.predict(X)

# Note que hay que sacarle la raiz al valor
np.sqrt(mse(y_true, y_predicted))